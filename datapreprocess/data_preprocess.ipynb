{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "\n",
      "Rows with any data:\n",
      "       flags                                        instruction category  \\\n",
      "0          B   question about cancelling order {{Order Number}}    ORDER   \n",
      "1        BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
      "2       BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
      "3         BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
      "4      BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
      "...      ...                                                ...      ...   \n",
      "26867     BL  I am waiting for a rebate of {{Refund Amount}}...   REFUND   \n",
      "26868    BIL  how to see if there is anything wrong with my ...   REFUND   \n",
      "26869   BLQZ  I'm waiting for a reimbjrsement of {{Currency ...   REFUND   \n",
      "26870     BL  I don't know what to do to see my reimbursemen...   REFUND   \n",
      "26871     BL  I need to know if there is anything new on the...   REFUND   \n",
      "\n",
      "             intent                                           response  \n",
      "0      cancel_order  I've understood you have a question regarding ...  \n",
      "1      cancel_order  I've been informed that you have a question ab...  \n",
      "2      cancel_order  I can sense that you're seeking assistance wit...  \n",
      "3      cancel_order  I understood that you need assistance with can...  \n",
      "4      cancel_order  I'm sensitive to the fact that you're facing f...  \n",
      "...             ...                                                ...  \n",
      "26867  track_refund  Thank you for sharing your situation regarding...  \n",
      "26868  track_refund  Ensuring the accuracy of your restitution is o...  \n",
      "26869  track_refund  Firstly, I genuinely understand the importance...  \n",
      "26870  track_refund  I've understood you're unsure about how to che...  \n",
      "26871  track_refund  It's completely understandable that you want t...  \n",
      "\n",
      "[26872 rows x 5 columns]\n",
      "\n",
      "Is the DataFrame empty? False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Replace 'your_dataset.csv' with the path to your dataset\n",
    "\n",
    "dataset = pd.read_csv('../dataset/Bitext.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Display the original DataFrame\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "\n",
    "# Check for rows with any data\n",
    "\n",
    "# This will return a boolean Series indicating if each row has any non-null values\n",
    "\n",
    "has_data = df.notnull().any(axis=1)\n",
    "\n",
    "# Display rows that have data\n",
    "\n",
    "rows_with_data = df[has_data]\n",
    "\n",
    "# Display the result\n",
    "\n",
    "print(\"\\nRows with any data:\")\n",
    "print(rows_with_data)\n",
    "\n",
    "# Optionally, if you want to check if the entire DataFrame is empty\n",
    "\n",
    "is_empty = df.empty\n",
    "print(\"\\nIs the DataFrame empty?\", is_empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of rows using shape: 26872\n",
      "Total number of rows using len(): 26872\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Using shape attribute\n",
    "\n",
    "total_rows_shape = df.shape[0]\n",
    "print(\"\\nTotal number of rows using shape:\", total_rows_shape)\n",
    "\n",
    "# Method 2: Using len() function\n",
    "\n",
    "total_rows_len = len(df)\n",
    "print(\"Total number of rows using len():\", total_rows_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flags Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique values: 394\n",
      "Total occurrences of all values: 26872\n"
     ]
    }
   ],
   "source": [
    "# Count unique values and their total occurrences\n",
    "\n",
    "unique_values_count = df['flags'].value_counts()\n",
    "total_values = unique_values_count.sum()\n",
    "\n",
    "# Display the total unique values and their combined total occurrences\n",
    "\n",
    "total_unique = len(unique_values_count)\n",
    "\n",
    "print(\"Total unique values:\", total_unique)\n",
    "print(\"Total occurrences of all values:\", total_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique values: 26872\n"
     ]
    }
   ],
   "source": [
    "# Count unique values and their total occurrences\n",
    "\n",
    "total_instruction = len(df['instruction'])\n",
    "\n",
    "# Display the total unique values and their combined total occurrences\n",
    "\n",
    "print(\"Total unique values:\", total_instruction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique values: 11\n",
      "Unique values: ['ACCOUNT', 'ORDER', 'REFUND', 'INVOICE', 'CONTACT', 'PAYMENT', 'FEEDBACK', 'DELIVERY', 'SHIPPING', 'SUBSCRIPTION', 'CANCEL']\n",
      "Total occurrences of all values: 26872\n"
     ]
    }
   ],
   "source": [
    "# Count unique values and their occurrences\n",
    "\n",
    "unique_values_count = df['category'].value_counts()\n",
    "total_sum = unique_values_count.sum()\n",
    "unique_values = unique_values_count.index.tolist()\n",
    "\n",
    "# Display the total unique values, their names, and summed total\n",
    "\n",
    "print(\"Total unique values:\", len(unique_values))\n",
    "print(\"Unique values:\", unique_values)\n",
    "print(\"Total occurrences of all values:\", total_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: ACCOUNT\n",
      "+----+------------+-----------------------+---------+\n",
      "|    | category   | intent                |   count |\n",
      "+====+============+=======================+=========+\n",
      "|  0 | ACCOUNT    | create_account        |     997 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  1 | ACCOUNT    | delete_account        |     995 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  2 | ACCOUNT    | edit_account          |    1000 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  3 | ACCOUNT    | recover_password      |     995 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  4 | ACCOUNT    | registration_problems |     999 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  5 | ACCOUNT    | switch_account        |    1000 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  6 | ACCOUNT    | Total                 |    5986 |\n",
      "+----+------------+-----------------------+---------+\n",
      "\n",
      "\n",
      "Category: CANCEL\n",
      "+----+------------+------------------------+---------+\n",
      "|    | category   | intent                 |   count |\n",
      "+====+============+========================+=========+\n",
      "|  0 | CANCEL     | check_cancellation_fee |     950 |\n",
      "+----+------------+------------------------+---------+\n",
      "|  1 | CANCEL     | Total                  |     950 |\n",
      "+----+------------+------------------------+---------+\n",
      "\n",
      "\n",
      "Category: CONTACT\n",
      "+----+------------+--------------------------+---------+\n",
      "|    | category   | intent                   |   count |\n",
      "+====+============+==========================+=========+\n",
      "|  0 | CONTACT    | contact_customer_service |    1000 |\n",
      "+----+------------+--------------------------+---------+\n",
      "|  1 | CONTACT    | contact_human_agent      |     999 |\n",
      "+----+------------+--------------------------+---------+\n",
      "|  2 | CONTACT    | Total                    |    1999 |\n",
      "+----+------------+--------------------------+---------+\n",
      "\n",
      "\n",
      "Category: DELIVERY\n",
      "+----+------------+------------------+---------+\n",
      "|    | category   | intent           |   count |\n",
      "+====+============+==================+=========+\n",
      "|  0 | DELIVERY   | delivery_options |     995 |\n",
      "+----+------------+------------------+---------+\n",
      "|  1 | DELIVERY   | delivery_period  |     999 |\n",
      "+----+------------+------------------+---------+\n",
      "|  2 | DELIVERY   | Total            |    1994 |\n",
      "+----+------------+------------------+---------+\n",
      "\n",
      "\n",
      "Category: FEEDBACK\n",
      "+----+------------+-----------+---------+\n",
      "|    | category   | intent    |   count |\n",
      "+====+============+===========+=========+\n",
      "|  0 | FEEDBACK   | complaint |    1000 |\n",
      "+----+------------+-----------+---------+\n",
      "|  1 | FEEDBACK   | review    |     997 |\n",
      "+----+------------+-----------+---------+\n",
      "|  2 | FEEDBACK   | Total     |    1997 |\n",
      "+----+------------+-----------+---------+\n",
      "\n",
      "\n",
      "Category: INVOICE\n",
      "+----+------------+---------------+---------+\n",
      "|    | category   | intent        |   count |\n",
      "+====+============+===============+=========+\n",
      "|  0 | INVOICE    | check_invoice |    1000 |\n",
      "+----+------------+---------------+---------+\n",
      "|  1 | INVOICE    | get_invoice   |     999 |\n",
      "+----+------------+---------------+---------+\n",
      "|  2 | INVOICE    | Total         |    1999 |\n",
      "+----+------------+---------------+---------+\n",
      "\n",
      "\n",
      "Category: ORDER\n",
      "+----+------------+--------------+---------+\n",
      "|    | category   | intent       |   count |\n",
      "+====+============+==============+=========+\n",
      "|  0 | ORDER      | cancel_order |     998 |\n",
      "+----+------------+--------------+---------+\n",
      "|  1 | ORDER      | change_order |     997 |\n",
      "+----+------------+--------------+---------+\n",
      "|  2 | ORDER      | place_order  |     998 |\n",
      "+----+------------+--------------+---------+\n",
      "|  3 | ORDER      | track_order  |     995 |\n",
      "+----+------------+--------------+---------+\n",
      "|  4 | ORDER      | Total        |    3988 |\n",
      "+----+------------+--------------+---------+\n",
      "\n",
      "\n",
      "Category: PAYMENT\n",
      "+----+------------+-----------------------+---------+\n",
      "|    | category   | intent                |   count |\n",
      "+====+============+=======================+=========+\n",
      "|  0 | PAYMENT    | check_payment_methods |     999 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  1 | PAYMENT    | payment_issue         |     999 |\n",
      "+----+------------+-----------------------+---------+\n",
      "|  2 | PAYMENT    | Total                 |    1998 |\n",
      "+----+------------+-----------------------+---------+\n",
      "\n",
      "\n",
      "Category: REFUND\n",
      "+----+------------+---------------------+---------+\n",
      "|    | category   | intent              |   count |\n",
      "+====+============+=====================+=========+\n",
      "|  0 | REFUND     | check_refund_policy |     997 |\n",
      "+----+------------+---------------------+---------+\n",
      "|  1 | REFUND     | get_refund          |     997 |\n",
      "+----+------------+---------------------+---------+\n",
      "|  2 | REFUND     | track_refund        |     998 |\n",
      "+----+------------+---------------------+---------+\n",
      "|  3 | REFUND     | Total               |    2992 |\n",
      "+----+------------+---------------------+---------+\n",
      "\n",
      "\n",
      "Category: SHIPPING\n",
      "+----+------------+-------------------------+---------+\n",
      "|    | category   | intent                  |   count |\n",
      "+====+============+=========================+=========+\n",
      "|  0 | SHIPPING   | change_shipping_address |     973 |\n",
      "+----+------------+-------------------------+---------+\n",
      "|  1 | SHIPPING   | set_up_shipping_address |     997 |\n",
      "+----+------------+-------------------------+---------+\n",
      "|  2 | SHIPPING   | Total                   |    1970 |\n",
      "+----+------------+-------------------------+---------+\n",
      "\n",
      "\n",
      "Category: SUBSCRIPTION\n",
      "+----+--------------+-------------------------+---------+\n",
      "|    | category     | intent                  |   count |\n",
      "+====+==============+=========================+=========+\n",
      "|  0 | SUBSCRIPTION | newsletter_subscription |     999 |\n",
      "+----+--------------+-------------------------+---------+\n",
      "|  1 | SUBSCRIPTION | Total                   |     999 |\n",
      "+----+--------------+-------------------------+---------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Group intents by category and count occurrences\n",
    "grouped_data = df.groupby(['category', 'intent']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the total counts and the number of unique intents per category\n",
    "category_summary = grouped_data.groupby('category').agg(\n",
    "    total_counts=('count', 'sum'),\n",
    "    unique_intents=('intent', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Create a summary table for each category\n",
    "for category in category_summary['category']:\n",
    "    category_data = grouped_data[grouped_data['category'] == category]\n",
    "    total_counts = category_data['count'].sum()\n",
    "    unique_intents = category_data['intent'].nunique()\n",
    "    total_row = pd.DataFrame({\n",
    "        'category': [category],\n",
    "        'intent': ['Total'],\n",
    "        'count': [total_counts]\n",
    "    })\n",
    "    category_data = pd.concat([category_data, total_row], ignore_index=True)\n",
    "    \n",
    "    # Convert the DataFrame to a tabular format\n",
    "    table = tabulate(category_data, headers='keys', tablefmt='grid')\n",
    "    \n",
    "    # Display the table\n",
    "    print(f\"Category: {category}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/reagan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Data Cleaning\n",
    "## Remove duplicates\n",
    "df_unique = df.drop_duplicates(subset=['instruction', 'response'])\n",
    "\n",
    "\n",
    "## Consistency in formatting (e.g., make all text lowercase)\n",
    "df['instruction'] = df['instruction'].str.lower()\n",
    "df['response'] = df['response'].str.lower()\n",
    "\n",
    "# 2. Normalization\n",
    "## Placeholder formatting consistency\n",
    "df['instruction'] = df['instruction'].str.replace(r'\\{\\{order number\\}\\}', '{{Order Number}}')\n",
    "\n",
    "# 4. Categorization Review\n",
    "## Check the balance of intents (if needed)\n",
    "intent_counts = df['intent'].value_counts()\n",
    "\n",
    "# 5. Tokenization (Using a tokenization library, e.g., nltk or sentencepiece)\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  # Download required resources for tokenizing\n",
    "\n",
    "df['tokenized_instructions'] = df['instruction'].apply(word_tokenize)\n",
    "\n",
    "\n",
    "# 8. Validation (Simple data quality check - Check for NaNs)\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# 9. Test Set Creation (Splitting the dataset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['intent'])\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42, stratify=test_df['intent'])\n",
    "\n",
    "# Save the preprocessed data to CSV\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "val_df.to_csv('val_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
